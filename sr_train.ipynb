{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "colored-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import ReLU, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-gilbert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "velvet-preserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_to_space(inp, scale):\n",
    "    return tf.nn.depth_to_space(inp, scale)\n",
    "\n",
    "\n",
    "def relu6(x):\n",
    "    return ReLU(max_value=6.0)(x)\n",
    "\n",
    "\n",
    "def _upscale(inp, inp_filter, scale):\n",
    "    x = depth_to_space(inp, scale)\n",
    "    x = Conv2D(inp_filter, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block(inp, out_filters, exp_ratio):\n",
    "    channel = K.image_data_format()\n",
    "    if channel == 'channel_last':\n",
    "        channel_axis = -1\n",
    "    else:\n",
    "        channel_axis = 1\n",
    "    inp_channel = K.int_shape(inp)[channel_axis]\n",
    "    exp_filter = inp_channel * exp_ratio\n",
    "    x = Conv2D(exp_filter, (1, 1), padding='same')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = relu6(x)\n",
    "    x = DepthwiseConv2D((3, 3), padding='same', strides=(2,2))(x)\n",
    "    x = relu6(x)\n",
    "    x = Conv2D(out_filters, (1, 1), padding='same')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def blocks(inp, out_filt, t, n):\n",
    "    x = block(inp, out_filt, t)\n",
    "    for i in range(1, n):\n",
    "        \n",
    "        x = block(x, out_filt, t)\n",
    "    return x\n",
    "\n",
    "\n",
    "def model(inp_shape):\n",
    "    inputs = Input(shape=inp_shape)\n",
    "    x = Conv2D(8, (3, 3), strides=(2, 2), padding='same', name='input_layer')(inputs)\n",
    "    x = blocks(x, 16, 1, 1)\n",
    "    x = blocks(x, 32, 6, 1)\n",
    "    x = blocks(x, 64, 6, 1)\n",
    "    x = _upscale(x, 32, 2)\n",
    "    x = _upscale(x, 48, 2)\n",
    "    x = depth_to_space(x, 4)\n",
    "    sr_model = Model(inputs, x)\n",
    "    sr_model.summary()\n",
    "    return sr_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eastern-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(inp_shape):\n",
    "#     inputs = Input(shape=inp_shape)\n",
    "#     x = Conv2D(32, (3, 3), strides=(2, 2), padding='same', name='input_layer')(inputs)\n",
    "#     x = blocks(x, 16, 1, 1, 1)\n",
    "#     x = blocks(x, 24, 6, 2, 2)\n",
    "#     x = blocks(x, 32, 6, 3, 2)\n",
    "#     x = _upscale(x, 32, 4)\n",
    "#     x = _upscale(x, 48, 4)\n",
    "#     x = depth_to_space(x, 4)\n",
    "#     sr_model = Model(inputs, x)\n",
    "#     sr_model.summary()\n",
    "#     return sr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "located-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cardiovascular-intellectual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "input_layer (Conv2D)         (None, 64, 64, 8)         224       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 64)        576       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 192)       3264      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 192)       768       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 32, 32, 192)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 16, 16, 192)       1920      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        6176      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 96)        3168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 96)        384       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 8, 8, 96)          960       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 8, 8, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          6208      \n",
      "_________________________________________________________________\n",
      "tf.nn.depth_to_space (TFOpLa (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 32)        544       \n",
      "_________________________________________________________________\n",
      "tf.nn.depth_to_space_1 (TFOp (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 48)        432       \n",
      "_________________________________________________________________\n",
      "tf.nn.depth_to_space_2 (TFOp (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 26,560\n",
      "Trainable params: 25,856\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "twelve-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pth = \"/media/nusrat/New Volume/div2k_dataset/\"\n",
    "val_hr_path = os.path.join(base_pth, \"DIV2K_valid_HR/\")\n",
    "val_lr_path = os.path.join(base_pth, \"DIV2K_valid_LR_mild/\")\n",
    "train_hr_path = os.path.join(base_pth, \"DIV2K_train_HR/\")\n",
    "train_lr_path = os.path.join(base_pth, \"DIV2K_train_LR_mild/\")\n",
    "# val_hr_img_names = os.list\n",
    "# val_lr_img_names\n",
    "# train_hr_img_names\n",
    "# train_lr_img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "manual-bundle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_lines = open(\"/media/nusrat/New Volume/div2k_dataset/validation.txt\", 'r')\n",
    "Lines = file_lines.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hazardous-priest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(Lines[0].split(\"_\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "particular-tyler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0\\n']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lines[0].split(\"_\")[-1].split(\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "successful-measure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(count.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self,  list_IDs, batch_size=4, dim=(128,128), n_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        #print(len(list_IDs))\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        #print(type(indexes))\n",
    "        #print(indexes)\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))        \n",
    "        y =np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "#             print(ID)\n",
    "            try:\n",
    "\n",
    "                # temp_img = cv2.imread(ID)\n",
    "\n",
    "                temp_img = []\n",
    "                temp_img_mask = []\n",
    "#                 img_names = os.listdir(ID)\n",
    "#                 file_names = {}\n",
    "#                 for img_name in img_names:\n",
    "#                     ind = img_name.split(\".\")[0]\n",
    "                    \n",
    "                    \n",
    "#                     # file_names[\"index\"] = ind\n",
    "#                     file_names[ind] = img_name\n",
    "#                 test_list = [int(i) for i in list(file_names.keys())]\n",
    "#                 ll = sorted(test_list)\n",
    "#                 img_list = []\n",
    "#                 for j in range(len(ll)):\n",
    "#                     img_list.append(file_names[str(ll[j])])\n",
    "#                 # print(img_list)\n",
    "                for im in range(0,45):\n",
    "                    img = cv2.imread(ID + \"/Abs_power/\" + str(im)+\".jpeg\")\n",
    "#                     print(img.shape)\n",
    "                    img = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "#                     dst = cv2.bitwise_and(img, mask)\n",
    "\n",
    "#                     temp_img_mask.append(dst)\n",
    "                    temp_img.append(img)\n",
    "            except:\n",
    "#                 print(ID)\n",
    "#                 print(self.labels[ID])\n",
    "#                 print(self.labels[ID] == 0)\n",
    "                break\n",
    "            temp_img = np.array(temp_img)\n",
    "            temp_img = temp_img/255.0\n",
    "#             temp_img_mask = np.array(temp_img_mask)\n",
    "#             temp_img_mask = temp_img_mask/255.0\n",
    "            data_ind = list(self.m_data.keys())\n",
    "            for ind in data_ind:\n",
    "                is_exist = ind in ID\n",
    "                if is_exist:\n",
    "                    Metadata[i] = np.float(self.m_data[ind]/255)\n",
    "                    #print(\"{} {}\".format(ind, ID))            \n",
    "            X[i] = temp_img\n",
    "            \n",
    "            \n",
    "        #             y[i] = self.labels[ID]\n",
    "                #             print(\"{}  {}\".format(ID, self.labels[ID]))\n",
    "                #             print(\"Heee  yyy \",type(y))\n",
    "#             if self.labels[ID] == 0:\n",
    "#                 y.append([1,0])\n",
    "#             elif self.labels[ID]==1:\n",
    "#                 y.append([0,1])\n",
    "            \n",
    "            \n",
    "            if self.labels[ID] == 0:\n",
    "                y.append(0)\n",
    "                \n",
    "            elif self.labels[ID]==1:\n",
    "                y.append(1)\n",
    "#         print(y)\n",
    "            \n",
    "#         for_smooth = tf.keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "#         Metadata = Metadata/255.0\n",
    "#         Metadata = np.asarray(Metadata)\n",
    "#         print(Metadata)\n",
    "#         print(y)\n",
    "#         print(for_smooth)\n",
    "#         print(y)\n",
    "\n",
    "       \n",
    "#         return [X, X_mask], y\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "image_names = []\n",
    "\n",
    "for c in classes:\n",
    "    \n",
    "   # x = glob.glob(base_pth+c+\"/O1\" + \"/*\")\n",
    "    x = glob.glob(base_pth + c  + \"/*\")\n",
    "    if c == \"Amyloid_negative\":\n",
    "        dd = x[0:60]\n",
    "    else:\n",
    "        dd = x\n",
    "    for ss in dd:\n",
    "        sss = glob.glob(ss+\"/*\")\n",
    "        for kk in sss:\n",
    "            \n",
    "            image_names = image_names + glob.glob(kk+\"/*\")\n",
    "    print(len(image_names))\n",
    "val_img_names = []\n",
    "\n",
    "for c in classes:\n",
    "   # x = glob.glob(base_pth+c+\"/O1\" + \"/*\")\n",
    "    x = glob.glob(val_pth+ c  + \"/*\")\n",
    "    if c == \"Amyloid_negative\":\n",
    "        dd = x[0:20]\n",
    "    else:\n",
    "        dd = x\n",
    "    for ss in dd:\n",
    "        sss = glob.glob(ss+\"/*\")\n",
    "        for kk in sss:\n",
    "            \n",
    "            val_img_names = val_img_names + glob.glob(kk+\"/*\")\n",
    "    print(len(val_img_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "seven-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_gen(path_to_images, data_type, path_save):\n",
    "    img_names = os.listdir(path_to_images)\n",
    "    img_names.sort()\n",
    "    data = open(path_save + data_type + \".txt\", \"w\")\n",
    "    for i in range(len(img_names)):\n",
    "        img = cv2.imread(path_to_images + img_names[i])\n",
    "        img_h = img.shape[0]\n",
    "        img_w = img.shape[1]\n",
    "        count_w = int(img_w / 128)\n",
    "        count_h = int(img_h / 64)\n",
    "        for w in range(count_w):\n",
    "            for h in range(count_h):\n",
    "                line = img_names[i] + \"_\"+str(w) + \"_\" + str(h) + \"\\n\"\n",
    "                data.write(line)\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "scheduled-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen(val_hr_path, 'validation_', base_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-election",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
